import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import csv

# Default
train_loss_default = [3.1948, 2.3621, 1.9732, 1.6599, 1.3678, 1.0924, 0.8405, 0.6466, 0.4937, 0.3944, 0.316, 0.2832, 0.2396, 0.2223, 0.1978, 0.1866, 0.1748, 0.1591, 0.1481, 0.1459, 0.1318, 0.1295, 0.1256, 0.1182, 0.1167, 0.1107, 0.1055, 0.1052, 0.0983, 0.0981, 0.0893, 0.0954, 0.0954, 0.0826, 0.0854, 0.0836, 0.0792, 0.0796, 0.0739, 0.0734, 0.0708, 0.07, 0.0693, 0.0648, 0.0701, 0.0628, 0.0655, 0.07, 0.0619, 0.0627]
train_acc_default = [0.23361999999999999, 0.39516000000000001, 0.47920000000000001, 0.55044000000000004, 0.62161999999999995, 0.69418000000000002, 0.76046000000000002, 0.81301999999999996, 0.85531999999999997, 0.88293999999999995, 0.90400000000000003, 0.91437999999999997, 0.92627999999999999, 0.93020000000000003, 0.93859999999999999, 0.94162000000000001, 0.94462000000000002, 0.94894000000000001, 0.95309999999999995, 0.95384000000000002, 0.95887999999999995, 0.95789999999999997, 0.95921999999999996, 0.96172000000000002, 0.96199999999999997, 0.96462000000000003, 0.96728000000000003, 0.96596000000000004, 0.96784000000000003, 0.96855999999999998, 0.97097999999999995, 0.97001999999999999, 0.96877999999999997, 0.97307999999999995, 0.97287999999999997, 0.97323999999999999, 0.97514000000000001, 0.97421999999999997, 0.97538000000000002, 0.97624, 0.97767999999999999, 0.97841999999999996, 0.97818000000000005, 0.97902, 0.97741999999999996, 0.97968, 0.97951999999999995, 0.97794000000000003, 0.97984000000000004, 0.98007999999999995]
test_loss_default = [3.9596, 3.1275, 3.16, 2.6754, 3.0017, 3.1689, 3.3489, 2.9755, 3.6495, 3.729, 3.8817, 4.2384, 3.793, 4.0166, 4.2488, 4.0933, 4.4555, 4.0659, 4.4717, 4.2016, 5.1369, 4.8186, 4.5595, 4.8654, 5.0128, 4.7386, 4.7736, 4.7716, 4.9709, 5.3511, 4.8061, 4.901, 5.0545, 4.8335, 5.0881, 4.8605, 5.1301, 5.0401, 5.3249, 5.6924, 5.0879, 5.1384, 4.94, 4.9602, 5.1902, 5.5457, 4.957, 5.2757, 5.3306, 5.6508]
test_acc_default = [0.16619999999999999, 0.24879999999999999, 0.28249999999999997, 0.37019999999999997, 0.33289999999999997, 0.35420000000000001, 0.36380000000000001, 0.4083, 0.36209999999999998, 0.36820000000000003, 0.37940000000000002, 0.35920000000000002, 0.40139999999999998, 0.38879999999999998, 0.37819999999999998, 0.39100000000000001, 0.38240000000000002, 0.4042, 0.3916, 0.4022, 0.35980000000000001, 0.38240000000000002, 0.40720000000000001, 0.3987, 0.38619999999999999, 0.40300000000000002, 0.39150000000000001, 0.39389999999999997, 0.39290000000000003, 0.3639, 0.40489999999999998, 0.41199999999999998, 0.39889999999999998, 0.41189999999999999, 0.40489999999999998, 0.4098, 0.40620000000000001, 0.3972, 0.39379999999999998, 0.38540000000000002, 0.39789999999999998, 0.41720000000000002, 0.40670000000000001, 0.41449999999999998, 0.40500000000000003, 0.39529999999999998, 0.42220000000000002, 0.40920000000000001, 0.40920000000000001, 0.39119999999999999]

# Best
train_loss_best = [3.6322, 2.8699, 2.6077, 2.4406, 2.3144, 2.2179, 2.1354, 2.0516, 1.9999, 1.9472, 1.9008, 1.855, 1.8179, 1.7772, 1.7405, 1.72, 1.6805, 1.6644, 1.6326, 1.6113, 1.5864, 1.5662, 1.5472, 1.5258, 1.5053, 1.4961, 1.4755, 1.4638, 1.4457, 1.4349, 1.4255, 1.4173, 1.3924, 1.3779, 1.3671, 1.3544, 1.3528, 1.3347, 1.3244, 1.3188, 1.3102, 1.3068, 1.2911, 1.2881, 1.2712, 1.2705, 1.2569, 1.2397, 1.2416, 1.2302]
train_acc_best = [0.15894, 0.28294000000000002, 0.33207999999999999, 0.36749999999999999, 0.39491999999999999, 0.41438000000000003, 0.43302000000000002, 0.45197999999999999, 0.46206000000000003, 0.47399999999999998, 0.48505999999999999, 0.49547999999999998, 0.50595999999999997, 0.51282000000000005, 0.52217999999999998, 0.52646000000000004, 0.53515999999999997, 0.53768000000000005, 0.54447999999999996, 0.54844000000000004, 0.55666000000000004, 0.56184000000000001, 0.56355999999999995, 0.56876000000000004, 0.57674000000000003, 0.57691999999999999, 0.58299999999999996, 0.58564000000000005, 0.59050000000000002, 0.59289999999999998, 0.59474000000000005, 0.59740000000000004, 0.60251999999999994, 0.60287999999999997, 0.60875999999999997, 0.61331999999999998, 0.61131999999999997, 0.61694000000000004, 0.62050000000000005, 0.62016000000000004, 0.62439999999999996, 0.62292000000000003, 0.62968000000000002, 0.62734000000000001, 0.63146000000000002, 0.63173999999999997, 0.63434000000000001, 0.63905999999999996, 0.64114000000000004, 0.64032]
test_loss_best = [2.9547, 2.5209, 2.2914, 2.1448, 2.0689, 1.9465, 1.9271, 1.8622, 1.8161, 1.7594, 1.7258, 1.7296, 1.6773, 1.656, 1.641, 1.6186, 1.6203, 1.5577, 1.5715, 1.5709, 1.573, 1.5428, 1.5296, 1.5114, 1.5176, 1.5078, 1.5082, 1.5126, 1.4828, 1.497, 1.4916, 1.467, 1.488, 1.4674, 1.473, 1.5067, 1.4251, 1.466, 1.4352, 1.4845, 1.4616, 1.4044, 1.4492, 1.4462, 1.441, 1.4945, 1.4372, 1.4125, 1.4496, 1.4422]
test_acc_best = [0.27029999999999998, 0.35570000000000002, 0.40079999999999999, 0.43140000000000001, 0.45610000000000001, 0.47660000000000002, 0.48280000000000001, 0.49959999999999999, 0.51190000000000002, 0.51459999999999995, 0.5252, 0.53680000000000005, 0.54100000000000004, 0.55210000000000004, 0.55030000000000001, 0.55910000000000004, 0.5595, 0.56530000000000002, 0.57010000000000005, 0.5726, 0.56769999999999998, 0.5806, 0.58169999999999999, 0.58120000000000005, 0.58279999999999998, 0.5887, 0.59179999999999999, 0.59040000000000004, 0.59550000000000003, 0.59289999999999998, 0.59530000000000005, 0.59830000000000005, 0.59699999999999998, 0.60099999999999998, 0.60440000000000005, 0.59319999999999995, 0.61019999999999996, 0.60450000000000004, 0.60780000000000001, 0.60029999999999994, 0.60050000000000003, 0.61199999999999999, 0.60389999999999999, 0.60040000000000004, 0.60880000000000001, 0.59989999999999999, 0.61329999999999996, 0.62080000000000002, 0.61099999999999999, 0.61209999999999998]

# 100 per category
train_loss_100 = [4.3615728294372555, 3.6822863014221192, 3.3817427017211914, 3.1645299018859863, 2.9720192310333253, 2.8173151756286621, 2.7147922107696534, 2.5989037887573243, 2.5131485542297365, 2.4228521076202392, 2.3239698162078857, 2.2808513801574706, 2.2397347526550293, 2.1524721633911135, 2.1104069154739378, 2.0401520732879637, 1.9673507568359374, 1.9314675971984863, 1.9150926504135133, 1.8512769229888917, 1.8237714193344117, 1.7787221706390381, 1.7406095333099365, 1.6777182079315185, 1.6326246982574464, 1.5751304368972778, 1.5540355985641479, 1.5319151807785034, 1.4989256372451782, 1.4369222167968749, 1.4223660182952882, 1.3964125848770141, 1.353758355140686, 1.3308162328720092, 1.3127982688903808, 1.2909464559555053, 1.266233183479309, 1.2440353427886963, 1.2266279441833496, 1.1979215684890747, 1.1729712324142456, 1.1590774858474731, 1.1151999217987061, 1.1049490383148193, 1.0714605774879455, 1.0717501659393311, 1.0519168049812317, 1.026327446269989, 1.0213432640075684, 1.0063847879409791]
train_acc_100 = [0.0746, 0.1421, 0.1883, 0.22120000000000001, 0.26079999999999998, 0.28739999999999999, 0.30809999999999998, 0.33169999999999999, 0.34749999999999998, 0.36940000000000001, 0.38600000000000001, 0.39950000000000002, 0.40329999999999999, 0.43169999999999997, 0.4375, 0.4491, 0.46400000000000002, 0.46970000000000001, 0.47849999999999998, 0.49309999999999998, 0.49349999999999999, 0.50580000000000003, 0.52290000000000003, 0.5252, 0.54190000000000005, 0.56040000000000001, 0.55389999999999995, 0.56779999999999997, 0.57509999999999994, 0.59040000000000004, 0.58999999999999997, 0.59350000000000003, 0.61299999999999999, 0.61370000000000002, 0.61880000000000002, 0.626, 0.63739999999999997, 0.63990000000000002, 0.63790000000000002, 0.64780000000000004, 0.65100000000000002, 0.65500000000000003, 0.67469999999999997, 0.67410000000000003, 0.68600000000000005, 0.68269999999999997, 0.68530000000000002, 0.69179999999999997, 0.69810000000000005, 0.69699999999999995]
test_loss_100 = [3.9822236015319823, 3.4866183132171629, 3.4365626068115236, 3.031682836532593, 3.0457566825866698, 2.9698040687561034, 2.7281083709716798, 2.8477267082214355, 2.7743785545349122, 2.7485280830383303, 2.6140429214477541, 2.5655638893127439, 2.6546685039520264, 2.5079628856658935, 2.4456594589233398, 2.5128486923217772, 2.4619881885528563, 2.6072999172210691, 2.4057397502899169, 2.5883763507843018, 2.5356208282470702, 2.4625466548919679, 2.4736883865356445, 2.3050973041534424, 2.3905739933013916, 2.3303107624053956, 2.4228809246063232, 2.3471331604003907, 2.3486928745269777, 2.3007135334014892, 2.4704204368591309, 2.3815382118225097, 2.3484733581542967, 2.3196621122360228, 2.3664706634521484, 2.2785368019104002, 2.3205238510131836, 2.4139479999542237, 2.4268673103332521, 2.3841782287597657, 2.3152012386322021, 2.362131125640869, 2.3577738033294677, 2.4795147834777831, 2.3476383466720581, 2.433650202178955, 2.470633486557007, 2.5022994548797608, 2.382851182937622, 2.5318967254638673]
test_acc_100 = [0.10000000000000001, 0.18129999999999999, 0.1958, 0.25559999999999999, 0.24890000000000001, 0.25659999999999999, 0.30969999999999998, 0.28910000000000002, 0.31419999999999998, 0.31190000000000001, 0.34820000000000001, 0.35570000000000002, 0.3397, 0.37509999999999999, 0.38090000000000002, 0.3695, 0.37030000000000002, 0.35949999999999999, 0.39079999999999998, 0.38790000000000002, 0.38190000000000002, 0.39179999999999998, 0.39360000000000001, 0.4194, 0.40529999999999999, 0.40849999999999997, 0.41520000000000001, 0.42370000000000002, 0.42320000000000002, 0.43259999999999998, 0.41620000000000001, 0.43180000000000002, 0.42330000000000001, 0.44409999999999999, 0.42780000000000001, 0.4476, 0.44769999999999999, 0.43740000000000001, 0.43630000000000002, 0.4365, 0.44950000000000001, 0.44800000000000001, 0.4395, 0.43130000000000002, 0.4516, 0.43980000000000002, 0.44779999999999998, 0.43409999999999999, 0.45839999999999997, 0.43230000000000002]

# 300 per category
train_loss_300 = [3.8800148132324219, 3.1386756371816, 2.8295493175506592, 2.6530923778533935, 2.5145118324279787, 2.4212278065999349, 2.3248569597880047, 2.2491224390665692, 2.1907850877126056, 2.1246710605621337, 2.0705321225484212, 2.0295656567891438, 1.9785567846934, 1.9261698085784913, 1.8862660091400147, 1.8478694562911988, 1.8125162592569988, 1.7803694659550984, 1.7471496296564737, 1.7241247769673664, 1.6901653821945191, 1.66490249265035, 1.6443758190790811, 1.6250197098414103, 1.5921497248967489, 1.5603934228897094, 1.5463756976445515, 1.5378699982325237, 1.5171280095418294, 1.4871617278416951, 1.473780946858724, 1.4560489881515504, 1.4339131959915161, 1.4226413562774658, 1.4119682886759439, 1.3991530790328979, 1.3674449681599934, 1.3710531523386638, 1.3349833094278971, 1.334949793879191, 1.309908768717448, 1.3174865781466165, 1.2978129990259806, 1.2963441062609355, 1.2744135965983072, 1.2573611279805501, 1.2519037214279174, 1.2431796106338502, 1.2316633422215779, 1.1967895105997721]
train_acc_300 = [0.12696666666666667, 0.23280000000000001, 0.29006666666666664, 0.32200000000000001, 0.34893333333333332, 0.36956666666666665, 0.39146666666666668, 0.40433333333333332, 0.41913333333333336, 0.43226666666666669, 0.44656666666666667, 0.45816666666666667, 0.4647, 0.47733333333333333, 0.4869, 0.49519999999999997, 0.50196666666666667, 0.50916666666666666, 0.51876666666666671, 0.51829999999999998, 0.53116666666666668, 0.53583333333333338, 0.54379999999999995, 0.54433333333333334, 0.5524, 0.5605, 0.56420000000000003, 0.56426666666666669, 0.57206666666666661, 0.57706666666666662, 0.5796, 0.58523333333333338, 0.59119999999999995, 0.59389999999999998, 0.59533333333333338, 0.59940000000000004, 0.60483333333333333, 0.60470000000000002, 0.61546666666666672, 0.61416666666666664, 0.62196666666666667, 0.61699999999999999, 0.62416666666666665, 0.62593333333333334, 0.63166666666666671, 0.63283333333333336, 0.63290000000000002, 0.63729999999999998, 0.63919999999999999, 0.64863333333333328]
test_loss_300 = [3.4417397964477541, 2.7970658332824705, 2.8886885986328124, 2.4696837383270265, 2.4330578769683839, 2.2895040397644042, 2.1674671070098879, 2.2434538879394532, 2.0533499313354491, 2.0386390415191649, 2.142249520111084, 2.0502081180572511, 1.883437735939026, 1.919162705039978, 1.8455047161102296, 1.9479974933624267, 1.876210715675354, 1.8681307220458985, 1.8312432964324952, 1.7840965982437134, 1.7739836910247804, 1.7517752923965455, 1.7555975381851197, 1.8411994186401368, 1.7071642255783082, 1.7607343311309815, 1.7607671279907227, 1.7508993101119996, 1.7044459581375122, 1.6826568540573119, 1.7073565355300904, 1.6893283417701721, 1.7298949504852295, 1.7192388278961181, 1.6794797952651979, 1.6791911386489868, 1.6738631950378418, 1.722298392868042, 1.7040467971801758, 1.6569214921951294, 1.6911274013519286, 1.6936450401306153, 1.7021078123092652, 1.6734522749900818, 1.6744848073959351, 1.6562925415039063, 1.694509626197815, 1.6615394870758056, 1.6458622032165526, 1.7120001754760743]
test_acc_300 = [0.18379999999999999, 0.3034, 0.2787, 0.37130000000000002, 0.37480000000000002, 0.40310000000000001, 0.42980000000000002, 0.4199, 0.46310000000000001, 0.46460000000000001, 0.44490000000000002, 0.45900000000000002, 0.49509999999999998, 0.48220000000000002, 0.50670000000000004, 0.48309999999999997, 0.505, 0.50370000000000004, 0.50870000000000004, 0.52400000000000002, 0.5242, 0.53380000000000005, 0.53410000000000002, 0.51970000000000005, 0.54079999999999995, 0.52880000000000005, 0.5323, 0.54349999999999998, 0.54659999999999997, 0.54710000000000003, 0.5464, 0.5544, 0.54959999999999998, 0.54400000000000004, 0.55220000000000002, 0.55700000000000005, 0.55559999999999998, 0.54820000000000002, 0.55969999999999998, 0.56389999999999996, 0.55730000000000002, 0.56069999999999998, 0.55379999999999996, 0.55779999999999996, 0.5595, 0.56340000000000001, 0.56430000000000002, 0.57279999999999998, 0.57250000000000001, 0.55940000000000001]

# Shallow
train_loss_shallow = [3.8236895483398436, 3.3329700573730467, 3.1753581795501709, 3.0816105527496336, 3.0117014931488035, 2.9631987026214599, 2.9158025133514403, 2.8762927749633791, 2.8433475323486328, 2.8126046847534178, 2.7834915116882324, 2.7652407067871092, 2.7412854854583739, 2.7159677297210694, 2.7089826178741454, 2.6860018009185791, 2.6730700499725342, 2.660721926727295, 2.6487086167144773, 2.6433681201934816, 2.6189063893127442, 2.6146410701751708, 2.5997229315185546, 2.5901306124877927, 2.5810678856658935, 2.5702855499267576, 2.5574252059173586, 2.5527935229492189, 2.5480817221069336, 2.5400138145446776, 2.5407018356323241, 2.5250288894653319, 2.5213024816894531, 2.5146851933288574, 2.5056613105010985, 2.5102125965881346, 2.5013583609008787, 2.4916954272460936, 2.4956299903106691, 2.4867762796783448, 2.4768425543975829, 2.4766227545928956, 2.4696448973083496, 2.4627082550048827, 2.4653722047424318, 2.4585165870666503, 2.4515800232696532, 2.447485540084839, 2.4459100362396242, 2.4422418091583253]
train_acc_shallow = [0.1305, 0.20141999999999999, 0.23082, 0.24826000000000001, 0.26094000000000001, 0.26963999999999999, 0.27964, 0.28602, 0.29282000000000002, 0.29630000000000001, 0.30502000000000001, 0.30969999999999998, 0.31315999999999999, 0.31731999999999999, 0.31957999999999998, 0.3231, 0.32747999999999999, 0.32835999999999999, 0.33150000000000002, 0.33167999999999997, 0.33916000000000002, 0.33928000000000003, 0.34000000000000002, 0.34627999999999998, 0.34532000000000002, 0.34998000000000001, 0.35221999999999998, 0.35033999999999998, 0.35321999999999998, 0.35327999999999998, 0.35598000000000002, 0.35487999999999997, 0.35770000000000002, 0.35996, 0.36143999999999998, 0.36105999999999999, 0.36409999999999998, 0.36403999999999997, 0.36309999999999998, 0.36548000000000003, 0.37008000000000002, 0.36731999999999998, 0.36814000000000002, 0.36725999999999998, 0.36742000000000002, 0.36787999999999998, 0.37265999999999999, 0.37337999999999999, 0.37472, 0.37452000000000002]
test_loss_shallow = [3.1786831306457519, 2.9335186687469483, 2.8124471691131592, 2.7757680114746095, 2.6702761386871336, 2.6244584625244141, 2.5929158073425294, 2.5857466445922852, 2.5322399621963503, 2.5115642698287965, 2.4763561721801759, 2.4786255634307861, 2.4407453308105467, 2.4196836135864257, 2.4308331863403319, 2.4078421157836916, 2.396584527206421, 2.3624081907272338, 2.3742706630706789, 2.3571171123504637, 2.3272356834411623, 2.3321622566223144, 2.3132917884826658, 2.3336698896408081, 2.2841953094482421, 2.3143335330963133, 2.2996426628112792, 2.2697312480926515, 2.2628352836608885, 2.2773730712890625, 2.2746985874176024, 2.2709823101043702, 2.2439359880447389, 2.2486939271926878, 2.2387600166320802, 2.251710681915283, 2.2414238517761231, 2.2548480422973634, 2.2227669940948487, 2.2247927177429201, 2.2427932960510253, 2.2497624771118163, 2.2134083087921144, 2.1980092405319214, 2.210561492919922, 2.2030109203338624, 2.2040204490661619, 2.2128421871185302, 2.2006057106018067, 2.1837146137237551]
test_acc_shallow = [0.23999999999999999, 0.28549999999999998, 0.3095, 0.31609999999999999, 0.3342, 0.34549999999999997, 0.35260000000000002, 0.3533, 0.36470000000000002, 0.3715, 0.37290000000000001, 0.37830000000000003, 0.38400000000000001, 0.38779999999999998, 0.38590000000000002, 0.39179999999999998, 0.39679999999999999, 0.40570000000000001, 0.3977, 0.40610000000000002, 0.41420000000000001, 0.41039999999999999, 0.41239999999999999, 0.40410000000000001, 0.42530000000000001, 0.41560000000000002, 0.41710000000000003, 0.42270000000000002, 0.42499999999999999, 0.42609999999999998, 0.42420000000000002, 0.42270000000000002, 0.4335, 0.43509999999999999, 0.43190000000000001, 0.432, 0.4299, 0.4254, 0.437, 0.43590000000000001, 0.436, 0.42959999999999998, 0.44040000000000001, 0.44080000000000003, 0.44040000000000001, 0.44590000000000002, 0.43919999999999998, 0.439, 0.44090000000000001, 0.44440000000000002]

# Deep
train_loss_deep = [3.7527377423858641, 2.9518288585662842, 2.6383141722106935, 2.4439700965118409, 2.3066788486862184, 2.2008412012481688, 2.0957784066009522, 2.0012894927978517, 1.9412838395690919, 1.8710898843002319, 1.8233207402420044, 1.7689640511322022, 1.7125913375091553, 1.6763550868988037, 1.6387648650741578, 1.5924104452514649, 1.559887635383606, 1.5276067832183837, 1.5059122234344482, 1.4675398159790038, 1.4440185307693481, 1.4186533374023438, 1.3945568454360961, 1.3789389947891235, 1.3600608560180665, 1.3385117641067505, 1.3033485712432862, 1.2958183172225952, 1.2775023791122437, 1.2613657254981994, 1.2558966815567016, 1.2307555237197876, 1.2036049215316773, 1.1905410655212403, 1.1785051911163331, 1.1613488896179198, 1.1506054230499267, 1.1377487994194031, 1.1242812476348878, 1.1181386155319213, 1.1028244529724121, 1.0927306270217896, 1.0824060995483398, 1.0613220256614686, 1.0506059336090088, 1.0479905804252625, 1.0268138345146178, 1.0164077861404419, 1.0112137749099732, 1.004420124282837]
train_acc_deep = [0.13600000000000001, 0.26179999999999998, 0.32241999999999998, 0.36008000000000001, 0.39001999999999998, 0.41514000000000001, 0.43787999999999999, 0.45650000000000002, 0.47142000000000001, 0.48748000000000002, 0.49859999999999999, 0.51144000000000001, 0.52207999999999999, 0.53158000000000005, 0.54142000000000001, 0.55354000000000003, 0.56245999999999996, 0.56630000000000003, 0.57333999999999996, 0.58182, 0.59016000000000002, 0.59253999999999996, 0.60062000000000004, 0.60240000000000005, 0.61046, 0.61297999999999997, 0.62356, 0.62290000000000001, 0.62873999999999997, 0.63395999999999997, 0.63514000000000004, 0.63888, 0.64544000000000001, 0.6492, 0.6532, 0.65998000000000001, 0.65947999999999996, 0.66281999999999996, 0.6653, 0.66986000000000001, 0.67132000000000003, 0.67659999999999998, 0.67962, 0.68133999999999995, 0.68401999999999996, 0.68500000000000005, 0.69384000000000001, 0.69510000000000005, 0.69577999999999995, 0.69703999999999999]
test_loss_deep = [3.6699625225067138, 2.7955794246673582, 2.6932680271148683, 2.4782451446533202, 2.1994565593719484, 2.2867823843002317, 1.9979386863708497, 1.8748096084594728, 1.8729690567016601, 1.7536869554519654, 1.6306970752716063, 1.7838138389587401, 1.7311161991119384, 1.6111656887054444, 1.6401428909301758, 1.5623906257629394, 1.5690660379409791, 1.5813225538253783, 1.5011246412277222, 1.5507853134155274, 1.514670922279358, 1.5039949350357056, 1.5670753608703614, 1.4793635345458984, 1.474951505279541, 1.4680693424224853, 1.5135127983093262, 1.415480380821228, 1.4643379318237304, 1.4385350410461426, 1.4655797985076904, 1.4113149042129516, 1.4038729768753051, 1.4558523300170898, 1.4100778259277345, 1.444480774307251, 1.4257442985534667, 1.4096710014343261, 1.3761989305496216, 1.3943463479995728, 1.3953349498748779, 1.380472631263733, 1.367079836845398, 1.3760390073776245, 1.416166420173645, 1.3420585491180419, 1.3741838649749756, 1.3862004306793212, 1.3736557163238525, 1.4053293664932252]
test_acc_deep = [0.1749, 0.28889999999999999, 0.31319999999999998, 0.36399999999999999, 0.4209, 0.41620000000000001, 0.46289999999999998, 0.48909999999999998, 0.49280000000000002, 0.51570000000000005, 0.54669999999999996, 0.51429999999999998, 0.52529999999999999, 0.55640000000000001, 0.56089999999999995, 0.56869999999999998, 0.56789999999999996, 0.55910000000000004, 0.58020000000000005, 0.57399999999999995, 0.58479999999999999, 0.58479999999999999, 0.5756, 0.58850000000000002, 0.60029999999999994, 0.59309999999999996, 0.58389999999999997, 0.60470000000000002, 0.59709999999999996, 0.60450000000000004, 0.60019999999999996, 0.61509999999999998, 0.61460000000000004, 0.60440000000000005, 0.6149, 0.60540000000000005, 0.61870000000000003, 0.6099, 0.62050000000000005, 0.61399999999999999, 0.61660000000000004, 0.62639999999999996, 0.62580000000000002, 0.63419999999999999, 0.61970000000000003, 0.62880000000000003, 0.627, 0.62050000000000005, 0.62949999999999995, 0.62539999999999996]

# CIFAR-10
train_loss_cifar10 = [1.5675663036727905, 1.119722973060608, 1.029509419555664, 0.9799627920722962, 0.96020402303695673, 0.93515387495040891, 0.91696670652389523, 0.90588824136734014, 0.89626062170028686, 0.88660817127227787, 0.88220014713287354, 0.87175335123062136, 0.86570765352249146, 0.8569351139259338, 0.85557047815322873, 0.85503544727325442, 0.84347576749801634, 0.84165277992248533, 0.84227387083053584, 0.83550964977264408, 0.82638174083709715, 0.82794787670135495, 0.81967981241226195, 0.81820749061584475, 0.81705577745437619, 0.80934972333908084, 0.80853535108566288, 0.80759251310348512, 0.80039074901580809, 0.8009490905570984, 0.79948795763015745, 0.79783391611099241, 0.79784204153060911, 0.79355126567840573, 0.78999679695129399, 0.79365563554763796, 0.78158673601150508, 0.78279482490539554, 0.78797626546859745, 0.77702534088134767, 0.77441227346420283, 0.77951321887969971, 0.7773997804069519, 0.77572911342620854, 0.77248467603683468, 0.76453977106094362, 0.76949963958740231, 0.76879886848449708, 0.76187791410446171, 0.75928325410842901]
train_acc_cifar10 = [0.47227999999999998, 0.61341999999999997, 0.63588, 0.65132000000000001, 0.65773999999999999, 0.66634000000000004, 0.67283999999999999, 0.67712000000000006, 0.68035999999999996, 0.68406, 0.68691999999999998, 0.68922000000000005, 0.69030000000000002, 0.69433999999999996, 0.69703999999999999, 0.69581999999999999, 0.70016, 0.70542000000000005, 0.69813999999999998, 0.70335999999999999, 0.70538000000000001, 0.70684000000000002, 0.70953999999999995, 0.70953999999999995, 0.71011999999999997, 0.71252000000000004, 0.71306000000000003, 0.71433999999999997, 0.71531999999999996, 0.71636, 0.71875999999999995, 0.71726000000000001, 0.71650000000000003, 0.71792, 0.72089999999999999, 0.71899999999999997, 0.72341999999999995, 0.72414000000000001, 0.72145999999999999, 0.72563999999999995, 0.7248, 0.72582000000000002, 0.72667999999999999, 0.72606000000000004, 0.72528000000000004, 0.72897999999999996, 0.72816000000000003, 0.72724, 0.73014000000000001, 0.73129999999999995]
test_loss_cifar10 = [1.0712524518966675, 0.90187943086624145, 0.83718518466949465, 0.80612130756378175, 0.78689461317062381, 0.76273701276779171, 0.7472136297225952, 0.74161264939308169, 0.73853026561737056, 0.72170835342407225, 0.71771550054550171, 0.71136366872787471, 0.70700245523452754, 0.71575933294296268, 0.68779264497756953, 0.69821166114807132, 0.68366446695327754, 0.68885873603820802, 0.68354920310974121, 0.68770096712112427, 0.67200119733810426, 0.66634199104309078, 0.67911755266189577, 0.66568040695190434, 0.67077087373733524, 0.6675361342430115, 0.65648302669525149, 0.65816244001388546, 0.65521145839691164, 0.65402885894775387, 0.65986207628250126, 0.65083148908615107, 0.64994933576583858, 0.64820623874664307, 0.646639066696167, 0.64666316313743588, 0.64591794290542603, 0.63963577222824097, 0.64536596384048461, 0.62834925012588505, 0.64620560560226437, 0.62850935544967657, 0.63333582735061644, 0.63699349708557129, 0.62923309183120724, 0.63273755226135253, 0.63793807725906371, 0.62246104145050052, 0.62565203809738157, 0.61710951972007755]
test_acc_cifar10 = [0.66000000000000003, 0.69140000000000001, 0.70550000000000002, 0.71260000000000001, 0.72040000000000004, 0.72699999999999998, 0.73670000000000002, 0.73560000000000003, 0.73719999999999997, 0.74029999999999996, 0.74639999999999995, 0.74690000000000001, 0.74880000000000002, 0.74570000000000003, 0.753, 0.75229999999999997, 0.75480000000000003, 0.75339999999999996, 0.75949999999999995, 0.75609999999999999, 0.76060000000000005, 0.76780000000000004, 0.755, 0.76380000000000003, 0.76129999999999998, 0.76349999999999996, 0.76770000000000005, 0.76470000000000005, 0.76780000000000004, 0.76910000000000001, 0.76570000000000005, 0.76900000000000002, 0.77170000000000005, 0.76859999999999995, 0.76939999999999997, 0.77259999999999995, 0.76939999999999997, 0.7732, 0.77180000000000004, 0.77729999999999999, 0.77159999999999995, 0.77859999999999996, 0.77429999999999999, 0.77629999999999999, 0.77680000000000005, 0.77649999999999997, 0.77580000000000005, 0.78149999999999997, 0.77749999999999997, 0.78380000000000005]


data = [train_loss_default, test_loss_default,
        train_acc_default, test_acc_default,
        train_loss_best, test_loss_best,
        train_acc_best, test_acc_best,
        train_loss_100, test_loss_100,
        train_acc_100, test_acc_100,
        train_loss_300, test_loss_300,
        train_acc_300, test_acc_300,
        train_loss_shallow, test_loss_shallow,
        train_acc_shallow, test_acc_shallow,
        train_loss_deep, test_loss_deep,
        train_acc_deep, test_acc_deep,
        train_loss_cifar10, train_acc_cifar10,
        test_loss_cifar10, test_acc_cifar10]

def extract(file):
    with open(file) as f:
        reader = csv.reader(f)
        plot = list(reader)
        return plot

def plot_loss(train, test, name):
    plt.gca().set_xlim([0, 50])
    plt.gca().set_ylim([0, 10])
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.plot(train)
    plt.plot(test)
    plt.legend(['Train', 'Test'], loc='best')
    plt.savefig("%s.png" % name)
    plt.clf()

def plot_accuracy(train, test, name):
    plt.gca().set_xlim([0, 50])
    plt.gca().set_ylim([0, 1])
    plt.xlabel('epoch')
    plt.ylabel('accuracy')
    plt.plot(train)
    plt.plot(test)
    plt.legend(['Train', 'Test'], loc='best')
    plt.savefig("%s.png" % name)
    plt.clf()

# data = extract('output.csv')
files = ["default_loss", "default_accuracy", "best_loss", "best_accuracy",
         "100_loss", "100_accuracy", "300_loss", "300_accuracy",
         "shallow_loss", "shallow_accuracy", "deep_loss", "deep_accuracy",
         "cifar10_loss", "cifar10_accuracy"]
for i in range(len(files) / 2):
    plot_loss(data[4 * i], data[4 * i + 1], files[2 * i])
    plot_accuracy(data[4 * i + 2], data[4 * i + 3], files[2 * i + 1])
# plot_loss(train_loss_default, test_loss_default, "default_loss")
# plot_accuracy(train_acc_default, test_acc_default, "default_accuracy")
# plot_loss(train_loss_best, test_loss_best, "best_loss")
# plot_accuracy(train_acc_best, test_acc_best, "best_accuracy")
# plot_loss(train_loss_100, test_loss_100, "100_loss")
# plot_accuracy(train_acc_100, test_acc_100, "100_accuracy")
# plot_loss(train_loss_300, test_loss_300, "300_loss")
# plot_accuracy(train_acc_300, test_acc_300, "300_accuracy")
# plot_loss(train_loss_shallow, test_loss_shallow, "shallow_loss")
# plot_accuracy(train_acc_shallow, test_acc_shallow, "shallow_accuracy")
# plot_loss(train_loss_deep, test_loss_deep, "deep_loss")
# plot_accuracy(train_acc_deep, test_acc_deep, "deep_accuracy")
# plot_loss(train_loss_cifar10, test_loss_cifar10, "cifar10_loss")
# plot_accuracy(train_acc_cifar10, test_acc_cifar10, "cifar10_accuracy")
